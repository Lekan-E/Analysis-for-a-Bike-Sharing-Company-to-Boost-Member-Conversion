{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and extract new data from raw monthly datasets.\n",
    "\n",
    "### Contents\n",
    "1. Data cleaning\n",
    "2. Generate the revenue per trip.\n",
    "3. Get public holidays.\n",
    "4. Get and join weather data.\n",
    "5. Export data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import re # In-built regular expressions library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 5479096\n"
     ]
    }
   ],
   "source": [
    "# Import all the monthly csv dataset\n",
    "\n",
    "dec_20 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202012-divvy-tripdata.csv')\n",
    "jan_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202101-divvy-tripdata.csv')\n",
    "feb_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202102-divvy-tripdata.csv')\n",
    "march_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202103-divvy-tripdata.csv')\n",
    "april_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202104-divvy-tripdata.csv')\n",
    "may_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202105-divvy-tripdata.csv')\n",
    "jun_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202106-divvy-tripdata.csv')\n",
    "july_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202107-divvy-tripdata.csv')\n",
    "aug_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202108-divvy-tripdata.csv')\n",
    "sept_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202109-divvy-tripdata.csv')\n",
    "oct_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202110-divvy-tripdata.csv')\n",
    "nov_21 = pd.read_csv(r'/Users/Razak/Documents/Cyclistic Project/Cyclistic Project/cyclistic project/202111-divvy-tripdata.csv')\n",
    "\n",
    "\n",
    "# Join all months into a single dataframe\n",
    "months = [dec_20, jan_21, feb_21, march_21, april_21, may_21, jun_21, july_21, aug_21, sept_21, oct_21, nov_21]\n",
    "df_months = pd.concat(months)\n",
    "\n",
    "# Check the number of data points\n",
    "print(f'Number of data points: {df_months.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate ride_ids: 0\n",
      "No. duplicates after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df = df_months\n",
    "print('Number of duplicate ride_ids:',df['ride_id'].duplicated().sum())\n",
    "\n",
    "df = df.drop_duplicates(subset=['ride_id'])\n",
    "print('No. duplicates after dropping:', df['ride_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id               0\n",
       "rideable_type         0\n",
       "started_at            0\n",
       "ended_at              0\n",
       "start_station_name    0\n",
       "start_station_id      0\n",
       "end_station_name      0\n",
       "end_station_id        0\n",
       "start_lat             0\n",
       "start_lng             0\n",
       "end_lat               0\n",
       "end_lng               0\n",
       "member_casual         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle null rows\n",
    "\n",
    "# Drop rows without start and end time information\n",
    "df = df.dropna(subset= ['started_at','ended_at'])\n",
    "\n",
    "df = df.sort_values(by=['start_lat','start_lng'], ascending=True)\n",
    "\n",
    "# Forward fill the missing start_station_name and start_station_id\n",
    "df[['start_station_name', 'start_station_id']] = df[['start_station_name', 'start_station_id']].ffill().bfill()\n",
    "\n",
    "# Fill the end stations\n",
    "df = df.sort_values(by=['end_lat','end_lng'], ascending=True)\n",
    "# Forward fill the missing start_station_name and start_station_id\n",
    "df[['end_station_name', 'end_station_id','end_lat','end_lng']] = df[['end_station_name', 'end_station_id','end_lat','end_lng']].ffill().bfill()\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction\n",
    "df_clean = df\n",
    "\n",
    "# Funtion to preprocess datetime string, adding seconds if missing\n",
    "def preprocess_datetime(dt_str):\n",
    "    if pd.isna(dt_str):\n",
    "        return np.nan\n",
    "    if len(dt_str) == 16:  # Format is missing seconds (YYYY-MM-DD HH:MM)\n",
    "        return dt_str + ':00'\n",
    "    # Add leading zero to single-digit hours\n",
    "    if len(dt_str) == 15 and re.match(r'\\d{4}-\\d{2}-\\d{2} \\d:\\d{2}', dt_str):\n",
    "        return dt_str[:11] + '0' + dt_str[11:] + ':00'\n",
    "    \n",
    "    # Add leading zero to single-digit hours with missing seconds\n",
    "    if len(dt_str) == 14 and re.match(r'\\d{4}-\\d{2}-\\d{2} \\d:\\d{2}', dt_str):\n",
    "        return dt_str[:11] + '0' + dt_str[11:] + ':00'\n",
    "    return dt_str\n",
    "\n",
    "# Apply the preprocessing function to both columns\n",
    "df_clean['started_at'] = df_clean['started_at'].apply(preprocess_datetime)\n",
    "df_clean['ended_at'] = df_clean['ended_at'].apply(preprocess_datetime)\n",
    "\n",
    "# Convert to date time\n",
    "df_clean['started_at'] = pd.to_datetime(df_clean['started_at'],format='%Y-%m-%d %H:%M:%S')\n",
    "df_clean['ended_at'] = pd.to_datetime(df_clean['ended_at'],format='%Y-%m-%d %H:%M:%S')\n",
    "# Extract the month and day of the week\n",
    "df['day'] = df['started_at'].dt.day_name()\n",
    "df['month'] = df['started_at'].dt.strftime(\"%B\")\n",
    "\n",
    "# Find the ride duration in seconds\n",
    "df_clean['ride_duration'] = (df_clean['ended_at']-df_clean['started_at']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interquartile range: 910.0\n",
      "Lower Bound: -955.0\n",
      "Upper Bound: 2685.0\n",
      "Mean: 1209.2180638922916\n",
      "No of data points after cleaning: 5072961\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers\n",
    "\n",
    "p25 = df_clean['ride_duration'].quantile(0.25) # 25th percentile\n",
    "p50 = df_clean['ride_duration'].quantile(0.5) # 50th percentile\n",
    "p75 = df_clean['ride_duration'].quantile(0.75) # 75th percentile\n",
    "\n",
    "# Interquartile range\n",
    "iqr = p75 - p25\n",
    "print(f'Interquartile range: {iqr}')\n",
    "\n",
    "# Lower Limit\n",
    "lower_bound  = p25 - 1.5 * iqr\n",
    "print(f'Lower Bound: {lower_bound}')\n",
    "\n",
    "# Upper Limit\n",
    "upper_bound = p75 + 1.5 * iqr\n",
    "print(f'Upper Bound: {upper_bound}')\n",
    "\n",
    "# Mean\n",
    "print(f'Mean: {df_clean['ride_duration'].mean()}')\n",
    "\n",
    "# Eliminate outliers above the upper bound and negative ride durations\n",
    "df_clean = df_clean[(df_clean['ride_duration'] >= 0) & (df_clean['ride_duration'] <= upper_bound)]\n",
    "\n",
    "print(f'No of data points after cleaning: {df_clean.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour of the day\n",
    "df_clean['hour'] = df_clean['started_at'].dt.hour # extract the ride hour\n",
    "\n",
    "# function to assign time of day\n",
    "def time_of_day(row):\n",
    "    if 0 <= row['hour'] < 6:\n",
    "        return 'Early Morning'\n",
    "    elif 6 <= row['hour'] < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= row['hour'] < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= row['hour'] < 21:\n",
    "        return 'Evening'\n",
    "    elif 21 <= row['hour'] < 24:\n",
    "        return 'Night'\n",
    "    \n",
    "df_clean['time_of_day'] = df_clean.apply(time_of_day, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign seasons based on the month\n",
    "def assign_season(row):\n",
    "    if row['month'] in ['December', 'January', 'February']:\n",
    "        return 'Winter'\n",
    "    elif row['month'] in ['March', 'April', 'May']:\n",
    "        return 'Spring'\n",
    "    elif row['month'] in ['June', 'July', 'August']:\n",
    "        return 'Summer'\n",
    "    elif row['month'] in ['September', 'October', 'November']:\n",
    "        return 'Fall'\n",
    "    \n",
    "# Apply the function to assign seasons\n",
    "df_clean['season'] = df_clean.apply(assign_season, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate the revenue per trip\n",
    "For the revenue generated for each trip, I adopted a similar pricing schema used by a local bike sharing company, BIKE SHARE TORONTO. The pricing goes as follow:\n",
    "- Members:\n",
    "    - Unlocking Fee = $0\n",
    "    - Classic Bike  = $0.17/minute\n",
    "    - Electric Bike = $0.17/minute\n",
    "    - Docked Bike = $0.20/minute\n",
    "\n",
    "- Casual:\n",
    "    - Unlocking Fee = $1.35\n",
    "    - Classic Bike  = $0.20/minute\n",
    "    - Electric Bike = $0.35/minute\n",
    "    - Docked Bike = $0.40/minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_revenue(row):\n",
    "\n",
    "    ride_duration_mins = row['ride_duration']/60 # convert to minutes\n",
    "\n",
    "    if row['member_casual'] == 'casual':\n",
    "\n",
    "        unlocking_fee = 1.35 # Casual unlocking fee\n",
    "        if row['rideable_type'] == 'electric_bike':\n",
    "            return unlocking_fee + 0.35 * ride_duration_mins\n",
    "        elif row['rideable_type'] == 'classic_bike':\n",
    "            return unlocking_fee + 0.20 * ride_duration_mins\n",
    "        elif row['rideable_type'] == 'docked_bike':\n",
    "            return unlocking_fee + 0.40 * ride_duration_mins\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    elif row['member_casual'] == 'member':\n",
    "        if row['rideable_type'] == 'electric_bike':\n",
    "            return 0.17 * ride_duration_mins\n",
    "        elif row['rideable_type'] == 'classic_bike':\n",
    "            return 0.17 * ride_duration_mins\n",
    "        elif row['rideable_type'] == 'docked_bike':\n",
    "            return 0.20 * ride_duration_mins\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_clean['revenue'] = df_clean.apply(add_revenue, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get public holidays\n",
    "Here's my approach to achieve this:\n",
    "1. Get all public holidays in Chicago that year (2021) via web scraping\n",
    "2. Extract the date from the 'started_at' column\n",
    "3. Join with the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.timeanddate.com/holidays/us/2021'\n",
    "\n",
    "# Scrape the raw table\n",
    "holiday_data = pd.read_html(url)[0]\n",
    "\n",
    "# Drop first levl column of the multi-index\n",
    "holiday_data.columns = holiday_data.columns.droplevel(0)\n",
    "\n",
    "#renam column\n",
    "df_holiday = holiday_data.rename(columns={'Unnamed: 1_level_1': 'Day'})\n",
    "\n",
    "# Select needed columns and rows\n",
    "holidays = df_holiday[['Date','Day','Name']].iloc[1:-1].reset_index(drop=True)\n",
    "\n",
    "# Extract the date\n",
    "\n",
    "df_clean['start_date'] = df_clean['started_at'].dt.strftime(\"%b %d\")\n",
    "df_clean['start_day'] = df_clean['started_at'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Join \n",
    "holiday_df = pd.merge(df_clean, holidays, left_on ='start_date', right_on = 'Date', how = 'left').drop_duplicates(subset = 'ride_id')\n",
    "\n",
    "# get holiday columns\n",
    "def holiday(row):\n",
    "    if pd.isna(row['Name']):\n",
    "        return 'Not Holiday'\n",
    "    else:\n",
    "        return 'Holiday'\n",
    "    \n",
    "holiday_df['holiday'] = holiday_df.apply(holiday, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get and Join the daily weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import climate data\n",
    "weather_df = pd.read_csv(r'./Chicago,United States 2020-12-01 to 2021-12-01.csv')\n",
    "\n",
    "# Clean data\n",
    "# Convert the 'datetime' column to actual datetime objects\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], format='%Y-%m-%dT%H:%M:%S')\n",
    "weather_df['datetime'] = weather_df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_weather = weather_df[['datetime','conditions','icon','temp','humidity','windspeed']]\n",
    "\n",
    "holiday_df['start_date_hour'] = holiday_df['started_at'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "# Optionally convert it back to string format\n",
    "holiday_df['start_date_hour'] = holiday_df['start_date_hour'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "full_df = pd.merge(holiday_df, df_weather, left_on='start_date_hour', right_on = 'datetime', how ='left').drop_duplicates(subset = 'ride_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>holiday</th>\n",
       "      <th>start_date_hour</th>\n",
       "      <th>datetime</th>\n",
       "      <th>conditions</th>\n",
       "      <th>icon</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>temp_feel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>097BB436A70E5964</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-02-27 01:27:00</td>\n",
       "      <td>2021-02-27 02:09:00</td>\n",
       "      <td>Indiana Ave &amp; 133rd St</td>\n",
       "      <td>20240</td>\n",
       "      <td>Hegewisch Metra Station</td>\n",
       "      <td>20215</td>\n",
       "      <td>41.65</td>\n",
       "      <td>-87.54</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Holiday</td>\n",
       "      <td>2021-02-27 01:00:00</td>\n",
       "      <td>2021-02-27 01:00:00</td>\n",
       "      <td>Rain, Overcast</td>\n",
       "      <td>rain</td>\n",
       "      <td>2.4</td>\n",
       "      <td>81.47</td>\n",
       "      <td>10.1</td>\n",
       "      <td>Cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401BC56B23FA4A26</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-10-08 12:12:05</td>\n",
       "      <td>2021-10-08 12:35:25</td>\n",
       "      <td>Major Taylor Trail &amp; 124th St</td>\n",
       "      <td>20208</td>\n",
       "      <td>Hegewisch Metra Station</td>\n",
       "      <td>20215</td>\n",
       "      <td>41.67</td>\n",
       "      <td>-87.55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Holiday</td>\n",
       "      <td>2021-10-08 12:00:00</td>\n",
       "      <td>2021-10-08 12:00:00</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>22.0</td>\n",
       "      <td>66.12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type          started_at            ended_at  \\\n",
       "0  097BB436A70E5964  electric_bike 2021-02-27 01:27:00 2021-02-27 02:09:00   \n",
       "1  401BC56B23FA4A26  electric_bike 2021-10-08 12:12:05 2021-10-08 12:35:25   \n",
       "\n",
       "              start_station_name start_station_id         end_station_name  \\\n",
       "0         Indiana Ave & 133rd St            20240  Hegewisch Metra Station   \n",
       "1  Major Taylor Trail & 124th St            20208  Hegewisch Metra Station   \n",
       "\n",
       "  end_station_id  start_lat  start_lng  ...  Name      holiday  \\\n",
       "0          20215      41.65     -87.54  ...   NaN  Not Holiday   \n",
       "1          20215      41.67     -87.55  ...   NaN  Not Holiday   \n",
       "\n",
       "       start_date_hour             datetime        conditions  \\\n",
       "0  2021-02-27 01:00:00  2021-02-27 01:00:00    Rain, Overcast   \n",
       "1  2021-10-08 12:00:00  2021-10-08 12:00:00  Partially cloudy   \n",
       "\n",
       "                icon  temp humidity windspeed  temp_feel  \n",
       "0               rain   2.4    81.47      10.1       Cold  \n",
       "1  partly-cloudy-day  22.0    66.12      11.0       Warm  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to group the temperature into  (warm, cold, hot, cool)\n",
    "def categorize_temperature(row):\n",
    "    if row['temp'] < 10:\n",
    "        return 'Cold'\n",
    "    elif 10 <= row['temp'] < 20:\n",
    "        return 'Cool'\n",
    "    elif 20 <= row['temp'] < 30:\n",
    "        return 'Warm'\n",
    "    else:\n",
    "        return 'Hot'\n",
    "    \n",
    "# Apply the function\n",
    "full_df['temp_feel'] = full_df.apply(categorize_temperature, axis = 1)\n",
    "\n",
    "# Preview data\n",
    "full_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(r'./Cleaned Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- Weather: 'https://www.visualcrossing.com/weather/weather-data-services/Chicago,United%20States/metric/2020-12-01/2021-11-30'\n",
    "- Holidays: 'https://www.timeanddate.com/weather/usa/chicago/historic?month=1&year=2021'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
